# @package _global_

# to execute this experiment run:
# python train.py experiment=example

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["mnist", "simple_dense_net"]

seed: 12345

early_stopping:
  patience: 1000 # number of checks with no improvement after which training will be stopped

trainer:
  log_every_n_steps: 1
  accelerator: gpu
  fast_dev_run: False
  max_epochs: 1000
  limit_test_batches: 1.0

data:
  batch_size: 1024
  # batch_size: 32
  hparams:
    dataset_name: "wine-quality-red"

hydra:
  job:
    name: "uci_wine"
  run:
    dir: ${paths.log_dir}/${task_name}/A_FULL_uci_wine_0.8train/_${now:%Y-%m-%d}_${now:%H-%M-%S}_${hydra:job.name}
    # dir: ${paths.log_dir}/${task_name}/setup/_${now:%Y-%m-%d}_${now:%H-%M-%S}_${hydra:job.name}

logger:
  mlflow:
    # experiment_name: "uci-sanity-check-wine-500e-lr0.01"
    # experiment_name: "uci-eval-wine-500e-lr0.01"
    experiment_name: "FULL_uci_wine_0.8train"
    run_name: ${hydra:job.name} 

model:
  input_dim: 11
  output_dim: 1
  num_hypothesis: 1
  hidden_layers: [50]
  restrict_to_square: False
  hparams:
    learning_rate: 0.01
    denormalize_predictions: True
    h_optimization: True